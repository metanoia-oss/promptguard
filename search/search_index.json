{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PromptGuard","text":"<p>Never parse LLM output again.</p> <p>PromptGuard is a production-grade reliability layer that turns Large Language Models into safe, structured, testable software components.</p>"},{"location":"#what-it-does","title":"What it does","text":"<ul> <li>Schema-valid outputs \u2014 every time</li> <li>Automatic repair when models return bad data</li> <li>Prompt regression testing to catch drift</li> <li>Multi-provider \u2014 OpenAI, Anthropic, Google, local models</li> <li>CLI tooling for versioning, testing, and debugging</li> </ul>"},{"location":"#quick-example","title":"Quick example","text":"<pre><code>from promptguard import llm_call\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nresult = llm_call(\n    model=\"gpt-4o\",\n    prompt=\"John is 30 years old\",\n    schema=Person\n)\n\nprint(result.data)\n# Person(name='John', age=30)\n</code></pre> <p>If the model returns invalid output, PromptGuard automatically detects the violation, re-prompts, repairs, and returns guaranteed valid data.</p>"},{"location":"#install","title":"Install","text":"<pre><code>pip install llm-promptguard\n\n# With provider extras\npip install llm-promptguard[openai]\npip install llm-promptguard[anthropic]\npip install llm-promptguard[google]\npip install llm-promptguard[all]\n</code></pre>"},{"location":"#next-steps","title":"Next steps","text":"<ul> <li>Quick Start \u2014 get running in 5 minutes</li> <li>API Reference \u2014 full function and schema docs</li> <li>Providers \u2014 setup guides for each provider</li> <li>Testing \u2014 snapshot and regression testing</li> <li>CLI Reference \u2014 command-line tools</li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#core-functions","title":"Core Functions","text":""},{"location":"api/#llm_call","title":"<code>llm_call</code>","text":"<p>Synchronous structured LLM call with schema validation and auto-repair.</p> <pre><code>from promptguard import llm_call\n\nresult = llm_call(\n    model=\"gpt-4o\",\n    prompt=\"Extract the person's info\",\n    schema=Person,\n    max_retries=3,       # repair attempts on validation failure\n    temperature=0.0,\n)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>model</code> <code>str</code> Model identifier (e.g. <code>\"gpt-4o\"</code>, <code>\"claude-3-sonnet\"</code>) <code>prompt</code> <code>str</code> The prompt to send <code>schema</code> <code>type</code> Pydantic model, TypedDict, dataclass, or JSON schema dict <code>max_retries</code> <code>int</code> Number of repair attempts (default: 3) <code>temperature</code> <code>float</code> Sampling temperature <p>Returns: <code>LLMResult</code> with <code>.data</code> (validated instance) and <code>.metadata</code>.</p>"},{"location":"api/#allm_call","title":"<code>allm_call</code>","text":"<p>Async version of <code>llm_call</code>. Same parameters and behavior.</p> <pre><code>from promptguard import allm_call\n\nresult = await allm_call(\n    model=\"gpt-4o\",\n    prompt=\"Extract info\",\n    schema=Person,\n)\n</code></pre>"},{"location":"api/#schema-types","title":"Schema Types","text":"<p>PromptGuard accepts four schema types:</p>"},{"location":"api/#pydantic-basemodel","title":"Pydantic BaseModel","text":"<pre><code>from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n</code></pre>"},{"location":"api/#typeddict","title":"TypedDict","text":"<pre><code>from typing import TypedDict\n\nclass Person(TypedDict):\n    name: str\n    age: int\n</code></pre>"},{"location":"api/#dataclass","title":"dataclass","text":"<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n</code></pre>"},{"location":"api/#json-schema-dict","title":"JSON Schema (dict)","text":"<pre><code>schema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\"type\": \"string\"},\n        \"age\": {\"type\": \"integer\"}\n    },\n    \"required\": [\"name\", \"age\"]\n}\n</code></pre>"},{"location":"api/#configuration","title":"Configuration","text":"<p>PromptGuard auto-detects providers from model names. Provider-specific API keys are read from environment variables:</p> Provider Environment Variable OpenAI <code>OPENAI_API_KEY</code> Anthropic <code>ANTHROPIC_API_KEY</code> Google <code>GOOGLE_API_KEY</code> Local <code>LOCAL_LLM_BASE_URL</code> (for compatible servers)"},{"location":"api/#logging","title":"Logging","text":"<p>PromptGuard is silent by default. Enable logging with <code>configure_logging</code>:</p> <pre><code>from promptguard import configure_logging\n\n# Enable INFO level logging to stderr\nconfigure_logging(level=\"INFO\")\n\n# Enable DEBUG for detailed request/response info\nconfigure_logging(level=\"DEBUG\")\n\n# JSON format for production/log aggregation\nconfigure_logging(level=\"INFO\", format_style=\"json\")\n</code></pre> <p>Log levels: - <code>DEBUG</code> \u2014 Detailed request/response info - <code>INFO</code> \u2014 Repair attempts, successful operations - <code>WARNING</code> \u2014 Validation failures, retries - <code>ERROR</code> \u2014 Provider errors, repair exhaustion</p>"},{"location":"api/#exceptions","title":"Exceptions","text":"<p>PromptGuard provides specific exception types for error handling:</p> <pre><code>from promptguard import (\n    PromptGuardError,      # Base exception\n    ValidationError,       # Schema validation failed\n    RepairExhaustedError,  # Max repair attempts reached\n    ProviderError,         # Generic provider error\n    AuthenticationError,   # Invalid API key (401)\n    RateLimitError,        # Rate limit exceeded (429)\n    TimeoutError,          # Request timed out\n    ModelNotFoundError,    # Model doesn't exist (404)\n    ContextLengthExceededError,  # Prompt too long\n    ContentFilteredError,  # Content blocked by safety filters\n)\n</code></pre> <p>Example error handling:</p> <pre><code>from promptguard import llm_call, RateLimitError, AuthenticationError\nimport time\n\ntry:\n    result = llm_call(prompt=\"...\", model=\"gpt-4o\", schema=MySchema)\nexcept AuthenticationError:\n    print(\"Check your OPENAI_API_KEY\")\nexcept RateLimitError as e:\n    if e.retry_after:\n        time.sleep(e.retry_after)\n    # retry...\n</code></pre>"},{"location":"cli/","title":"CLI Reference","text":"<p>PromptGuard provides a command-line interface for managing prompts, running tests, and inspecting history.</p>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#promptguard-init","title":"<code>promptguard init</code>","text":"<p>Initialize PromptGuard in the current project. Creates the <code>.promptguard/</code> directory for snapshots and configuration.</p> <pre><code>promptguard init\n</code></pre>"},{"location":"cli/#promptguard-run","title":"<code>promptguard run</code>","text":"<p>Execute a prompt defined in a YAML file.</p> <pre><code>promptguard run prompt.yaml\n</code></pre>"},{"location":"cli/#promptguard-test","title":"<code>promptguard test</code>","text":"<p>Run regression tests against stored snapshots. Detects prompt drift and schema validation failures.</p> <pre><code>promptguard test\n</code></pre>"},{"location":"cli/#promptguard-history","title":"<code>promptguard history</code>","text":"<p>Show version history for tracked prompts.</p> <pre><code>promptguard history\n</code></pre>"},{"location":"cli/#promptguard-diff","title":"<code>promptguard diff</code>","text":"<p>Compare two versions of a prompt's output.</p> <pre><code>promptguard diff &lt;hash&gt;\n</code></pre>"},{"location":"cli/#promptguard-stats","title":"<code>promptguard stats</code>","text":"<p>Display statistics: success rates, repair frequency, and drift metrics.</p> <pre><code>promptguard stats\n</code></pre>"},{"location":"migration/","title":"Migration Guide","text":""},{"location":"migration/#from-raw-openai-sdk","title":"From raw OpenAI SDK","text":"<p>Before:</p> <pre><code>import json\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 30\"}],\n)\n\n# Hope for valid JSON\ntry:\n    data = json.loads(response.choices[0].message.content)\n    name = data[\"name\"]\n    age = data[\"age\"]\nexcept (json.JSONDecodeError, KeyError) as e:\n    # Now what?\n    raise\n</code></pre> <p>After:</p> <pre><code>from promptguard import llm_call\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nresult = llm_call(model=\"gpt-4o\", prompt=\"Extract: John is 30\", schema=Person)\nprint(result.data.name, result.data.age)\n# Guaranteed valid. Auto-repaired if needed.\n</code></pre>"},{"location":"migration/#from-instructor","title":"From Instructor","text":"<p>Before:</p> <pre><code>import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclient = instructor.from_openai(OpenAI())\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nperson = client.chat.completions.create(\n    model=\"gpt-4o\",\n    response_model=Person,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 30\"}],\n)\n</code></pre> <p>After:</p> <pre><code>from promptguard import llm_call\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nresult = llm_call(model=\"gpt-4o\", prompt=\"Extract: John is 30\", schema=Person)\nperson = result.data\n</code></pre>"},{"location":"migration/#what-you-gain-by-switching","title":"What you gain by switching","text":"Capability Instructor PromptGuard Schema validation Yes Yes Auto repair retries 1 Configurable (N) Multi-provider OpenAI-centric OpenAI, Anthropic, Google, Local Prompt versioning No Built-in Regression testing No Built-in CLI tooling No Yes TypedDict / dataclass support Limited Full"},{"location":"providers/","title":"Provider Setup","text":"<p>PromptGuard supports multiple LLM providers out of the box. Install the relevant extra and set your API key.</p>"},{"location":"providers/#openai","title":"OpenAI","text":"<pre><code>pip install llm-promptguard[openai]\nexport OPENAI_API_KEY=sk-...\n</code></pre> <pre><code>result = llm_call(model=\"gpt-4o\", prompt=\"...\", schema=MySchema)\n</code></pre> <p>Supported models: <code>gpt-4o</code>, <code>gpt-4o-mini</code>, <code>gpt-4-turbo</code>, and other OpenAI chat models.</p>"},{"location":"providers/#anthropic","title":"Anthropic","text":"<pre><code>pip install llm-promptguard[anthropic]\nexport ANTHROPIC_API_KEY=sk-ant-...\n</code></pre> <pre><code>result = llm_call(model=\"claude-3-sonnet-20240229\", prompt=\"...\", schema=MySchema)\n</code></pre> <p>Supported models: <code>claude-3-opus</code>, <code>claude-3-sonnet</code>, <code>claude-3-haiku</code>, and other Anthropic models.</p>"},{"location":"providers/#google-gemini","title":"Google Gemini","text":"<pre><code>pip install llm-promptguard[google]\nexport GOOGLE_API_KEY=...\n</code></pre> <pre><code>result = llm_call(model=\"gemini-1.5-pro\", prompt=\"...\", schema=MySchema)\n</code></pre> <p>Supported models: <code>gemini-1.5-pro</code>, <code>gemini-1.5-flash</code>, and other Gemini models.</p>"},{"location":"providers/#local-models-ollama-lm-studio-vllm","title":"Local Models (Ollama, LM Studio, vLLM)","text":"<p>Any OpenAI-compatible API server works with PromptGuard:</p> <pre><code>export OPENAI_API_BASE=http://localhost:11434/v1\n</code></pre> <pre><code>result = llm_call(model=\"llama3\", prompt=\"...\", schema=MySchema)\n</code></pre> <p>This works with:</p> <ul> <li>Ollama \u2014 <code>ollama serve</code> exposes an OpenAI-compatible endpoint</li> <li>LM Studio \u2014 enable the local server in settings</li> <li>vLLM \u2014 start with <code>--api-key</code> and <code>--served-model-name</code></li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#installation","title":"Installation","text":"<pre><code>pip install llm-promptguard[openai]\n</code></pre>"},{"location":"quickstart/#set-your-api-key","title":"Set your API key","text":"<pre><code>export OPENAI_API_KEY=sk-...\n</code></pre>"},{"location":"quickstart/#your-first-structured-call","title":"Your first structured call","text":"<pre><code>from promptguard import llm_call\nfrom pydantic import BaseModel\n\nclass Sentiment(BaseModel):\n    label: str\n    confidence: float\n\nresult = llm_call(\n    model=\"gpt-4o-mini\",\n    prompt=\"The product is fantastic and well-made\",\n    schema=Sentiment\n)\n\nprint(result.data)\n# Sentiment(label='positive', confidence=0.95)\n</code></pre>"},{"location":"quickstart/#async-usage","title":"Async usage","text":"<pre><code>from promptguard import allm_call\n\nresult = await allm_call(\n    model=\"gpt-4o\",\n    prompt=\"Summarize this document...\",\n    schema=Summary\n)\n</code></pre>"},{"location":"quickstart/#using-different-schema-types","title":"Using different schema types","text":"<p>PromptGuard supports Pydantic models, TypedDicts, dataclasses, and raw JSON schemas:</p> <pre><code>from typing import TypedDict\n\nclass Person(TypedDict):\n    name: str\n    age: int\n\nresult = llm_call(model=\"gpt-4o\", prompt=\"John is 30\", schema=Person)\n</code></pre> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n\nresult = llm_call(model=\"gpt-4o\", prompt=\"John is 30\", schema=Person)\n</code></pre>"},{"location":"quickstart/#running-regression-tests","title":"Running regression tests","text":"<pre><code>promptguard init    # set up in your project\npromptguard test    # run snapshot tests\n</code></pre> <p>See the Testing guide for details.</p>"},{"location":"testing/","title":"Testing &amp; Regression","text":"<p>PromptGuard includes built-in tools for snapshot testing and regression detection of LLM prompts.</p>"},{"location":"testing/#why-test-prompts","title":"Why test prompts?","text":"<p>LLM outputs change when:</p> <ul> <li>You update the prompt text</li> <li>The provider updates the model</li> <li>You switch models</li> <li>Temperature or parameters change</li> </ul> <p>Without testing, these changes break silently. PromptGuard makes prompt behavior testable.</p>"},{"location":"testing/#setup","title":"Setup","text":"<pre><code>promptguard init\n</code></pre> <p>This creates a <code>.promptguard/</code> directory in your project to store snapshots and history.</p>"},{"location":"testing/#running-tests","title":"Running tests","text":"<pre><code>promptguard test\n</code></pre> <p>This replays your registered prompts against their schemas, compares outputs to stored snapshots, and reports any drift.</p>"},{"location":"testing/#snapshot-workflow","title":"Snapshot workflow","text":"<ol> <li>Define prompts with schemas</li> <li>Run <code>promptguard test</code> to generate baseline snapshots</li> <li>On subsequent runs, PromptGuard compares new outputs to baselines</li> <li>Review and accept changes with <code>promptguard history</code> and <code>promptguard diff</code></li> </ol>"},{"location":"testing/#versioning","title":"Versioning","text":"<p>Every prompt execution is versioned. View history:</p> <pre><code>promptguard history\npromptguard diff &lt;hash&gt;\n</code></pre> <p>This lets you track how outputs change over time and catch regressions before they reach production.</p>"},{"location":"testing/#statistics","title":"Statistics","text":"<pre><code>promptguard stats\n</code></pre> <p>View success rates, repair frequency, and drift metrics across your prompts.</p>"},{"location":"blog/launch/","title":"We built an open-source reliability layer for LLMs","text":""},{"location":"blog/launch/#the-problem","title":"The problem","text":"<p>Every team building with LLMs hits the same wall: the model returns garbage.</p> <p>Not always. Not even often. But often enough to break production. Invalid JSON, missing fields, hallucinated keys, changed formats after a model update. The failure modes are endless and they all look the same \u2014 a crash at 2am, a corrupted pipeline, a broken agent.</p> <p>The standard fix is defensive parsing: <code>try/except</code>, regex extraction, retry loops, manual validation. It works until it doesn't. And it never composes.</p>"},{"location":"blog/launch/#why-existing-tools-arent-enough","title":"Why existing tools aren't enough","text":"<p>Instructor is a good library. It patches the OpenAI client to return Pydantic models. But it's OpenAI-centric, gives you one retry, and has no concept of prompt versioning or regression testing. When your model updates and outputs drift, you find out from your users.</p> <p>Outlines takes a different approach \u2014 constrained generation at the token level. Powerful for local models, but not applicable to API-based providers and not focused on the production reliability story.</p> <p>Neither gives you the full picture: validation + repair + versioning + testing + multi-provider support.</p>"},{"location":"blog/launch/#what-promptguard-does","title":"What PromptGuard does","text":"<p>PromptGuard is a reliability layer. You give it a prompt, a model, and a schema. It returns guaranteed valid structured data.</p> <pre><code>from promptguard import llm_call\nfrom pydantic import BaseModel\n\nclass Order(BaseModel):\n    product: str\n    quantity: int\n    price: float\n\norder = llm_call(\n    model=\"gpt-4o\",\n    prompt=\"Buy two iPhones for $999 each\",\n    schema=Order\n)\n# Order(product='iPhone', quantity=2, price=999.0)\n</code></pre> <p>When validation fails, PromptGuard automatically re-prompts with the error context and repairs the output. Configurable retries, not just one shot.</p> <p>It works with OpenAI, Anthropic, Google, and any OpenAI-compatible local server (Ollama, vLLM, LM Studio).</p> <p>It accepts Pydantic models, TypedDicts, dataclasses, and raw JSON schemas.</p> <p>It versions every prompt execution and provides CLI tools for regression testing:</p> <pre><code>promptguard test     # catch drift before production\npromptguard history  # track output changes over time\npromptguard diff     # compare versions\n</code></pre>"},{"location":"blog/launch/#who-its-for","title":"Who it's for","text":"<p>If you're running LLMs in production \u2014 agents, workflows, document parsing, voice systems, background jobs \u2014 and you need structured output that doesn't break, PromptGuard is the missing layer.</p>"},{"location":"blog/launch/#get-started","title":"Get started","text":"<pre><code>pip install llm-promptguard[openai]\n</code></pre> <ul> <li>GitHub</li> <li>Documentation</li> <li>Quick Start</li> </ul> <p>Apache 2.0 licensed. Contributions welcome.</p>"}]}